{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:22:36.217879Z",
     "iopub.status.busy": "2023-04-09T15:22:36.217169Z",
     "iopub.status.idle": "2023-04-09T15:22:58.942132Z",
     "shell.execute_reply": "2023-04-09T15:22:58.940816Z",
     "shell.execute_reply.started": "2023-04-09T15:22:36.217842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.0/769.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2.28.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (3.9.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (0.1.97)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (4.64.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==3.0.2) (2021.11.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==3.0.2) (3.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers==3.0.2) (4.11.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.2) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers==3.0.2) (3.11.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=7a3e1975dd333c395f9e9d65a58042398455ae5e1ebf51113ffa738cfb03e040\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/e0/77/05245143a5b31f65af6a21f7afd3219e9fa4896f918af45677\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.4\n",
      "    Uninstalling transformers-4.27.4:\n",
      "      Successfully uninstalled transformers-4.27.4\n",
      "Successfully installed sacremoses-0.0.53 tokenizers-0.8.1rc1 transformers-3.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:23:28.410803Z",
     "iopub.status.busy": "2023-04-09T15:23:28.409748Z",
     "iopub.status.idle": "2023-04-09T15:24:23.259497Z",
     "shell.execute_reply": "2023-04-09T15:24:23.258243Z",
     "shell.execute_reply.started": "2023-04-09T15:23:28.410740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-md==3.5.0) (3.5.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.21.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (59.8.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.4)\n",
      "Requirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.4.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.7/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.11.4)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:01.371010Z",
     "iopub.status.busy": "2023-04-09T15:44:01.370639Z",
     "iopub.status.idle": "2023-04-09T15:44:02.931020Z",
     "shell.execute_reply": "2023-04-09T15:44:02.929717Z",
     "shell.execute_reply.started": "2023-04-09T15:44:01.370975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "import re\n",
    "import utils\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from newsqa import NewsQaExample, NewsQaModel, create_dataset, get_single_prediction\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_md\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "en = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:02.935364Z",
     "iopub.status.busy": "2023-04-09T15:44:02.934522Z",
     "iopub.status.idle": "2023-04-09T15:44:03.291524Z",
     "shell.execute_reply": "2023-04-09T15:44:03.290295Z",
     "shell.execute_reply.started": "2023-04-09T15:44:02.935317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_char_ranges</th>\n",
       "      <th>is_answer_absent</th>\n",
       "      <th>is_question_bad</th>\n",
       "      <th>validated_answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./cnn/stories/43a488c2d73b4f34122fc92c8df04670...</td>\n",
       "      <td>When was the plane crash?</td>\n",
       "      <td>2794:2805,372:382|398:410|372:382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"none\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./cnn/stories/91607b09ab00b8dff5d7b98387ed132a...</td>\n",
       "      <td>Where has Musharraf lived in exile?</td>\n",
       "      <td>1018:1035|1008:1035|1018:1035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./cnn/stories/c674fdceb339915df2a9de1a0bd3007c...</td>\n",
       "      <td>What is he leaving?</td>\n",
       "      <td>529:543|None|237:252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333333333</td>\n",
       "      <td>{\"237:252\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./cnn/stories/a0c2d26c2ebecd53dcecc9ea04ae8c5a...</td>\n",
       "      <td>What should the president understand?</td>\n",
       "      <td>None|4317:4469</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{\"4317:4469\": 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./cnn/stories/ad2af6c1362a3f84000edd71fd752ad6...</td>\n",
       "      <td>Bush commutes whose sentence?</td>\n",
       "      <td>103:129,366:380,384:397,92:103|None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{\"103:129\": 2, \"366:380\": 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            story_id  \\\n",
       "0  ./cnn/stories/43a488c2d73b4f34122fc92c8df04670...   \n",
       "1  ./cnn/stories/91607b09ab00b8dff5d7b98387ed132a...   \n",
       "2  ./cnn/stories/c674fdceb339915df2a9de1a0bd3007c...   \n",
       "3  ./cnn/stories/a0c2d26c2ebecd53dcecc9ea04ae8c5a...   \n",
       "4  ./cnn/stories/ad2af6c1362a3f84000edd71fd752ad6...   \n",
       "\n",
       "                                question                   answer_char_ranges  \\\n",
       "0              When was the plane crash?    2794:2805,372:382|398:410|372:382   \n",
       "1    Where has Musharraf lived in exile?        1018:1035|1008:1035|1018:1035   \n",
       "2                    What is he leaving?                 529:543|None|237:252   \n",
       "3  What should the president understand?                       None|4317:4469   \n",
       "4          Bush commutes whose sentence?  103:129,366:380,384:397,92:103|None   \n",
       "\n",
       "   is_answer_absent is_question_bad             validated_answers  \n",
       "0               0.0             0.0                   {\"none\": 2}  \n",
       "1               0.0             0.0                           NaN  \n",
       "2               0.0  0.333333333333                {\"237:252\": 2}  \n",
       "3               0.5             0.5              {\"4317:4469\": 2}  \n",
       "4               0.0             0.5  {\"103:129\": 2, \"366:380\": 1}  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading in the dataset\n",
    "data = pd.read_csv('/kaggle/working/news111/newsqa-data-v1.csv')\n",
    "# Getting a sample from the dataset\n",
    "data = data.sample(frac = 0.10, random_state = 9)\n",
    "data = data.reset_index(drop = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:04.182465Z",
     "iopub.status.busy": "2023-04-09T15:44:04.181204Z",
     "iopub.status.idle": "2023-04-09T15:44:04.190914Z",
     "shell.execute_reply": "2023-04-09T15:44:04.189831Z",
     "shell.execute_reply.started": "2023-04-09T15:44:04.182426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11963"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of the dataset\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:04.799919Z",
     "iopub.status.busy": "2023-04-09T15:44:04.799522Z",
     "iopub.status.idle": "2023-04-09T15:44:04.821317Z",
     "shell.execute_reply": "2023-04-09T15:44:04.819967Z",
     "shell.execute_reply.started": "2023-04-09T15:44:04.799886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numeric and remove non-numeric rows\n",
    "data = data[pd.to_numeric(data['is_question_bad'], errors = 'coerce').notnull()]\n",
    "data['is_question_bad'] = data['is_question_bad'].astype(float)\n",
    "# Number of bad questions\n",
    "len(data[data['is_question_bad'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:05.294204Z",
     "iopub.status.busy": "2023-04-09T15:44:05.293856Z",
     "iopub.status.idle": "2023-04-09T15:44:05.305172Z",
     "shell.execute_reply": "2023-04-09T15:44:05.304121Z",
     "shell.execute_reply.started": "2023-04-09T15:44:05.294172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove all bad questions/questions that don't make any sense\n",
    "data = data[data['is_question_bad'] == 0]\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:06.179520Z",
     "iopub.status.busy": "2023-04-09T15:44:06.178757Z",
     "iopub.status.idle": "2023-04-09T15:44:06.187963Z",
     "shell.execute_reply": "2023-04-09T15:44:06.185059Z",
     "shell.execute_reply.started": "2023-04-09T15:44:06.179481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8769"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final data size\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:06.838385Z",
     "iopub.status.busy": "2023-04-09T15:44:06.837759Z",
     "iopub.status.idle": "2023-04-09T15:44:07.213154Z",
     "shell.execute_reply": "2023-04-09T15:44:07.211963Z",
     "shell.execute_reply.started": "2023-04-09T15:44:06.838346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word counts in questions\n",
    "cv = CountVectorizer(stop_words = ['the', 'is', 'was', 'of', 'to', 'in'])\n",
    "dtm = cv.fit_transform(data['question']).toarray()\n",
    "\n",
    "word_counts = dtm.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:07.386804Z",
     "iopub.status.busy": "2023-04-09T15:44:07.386178Z",
     "iopub.status.idle": "2023-04-09T15:44:07.399293Z",
     "shell.execute_reply": "2023-04-09T15:44:07.398030Z",
     "shell.execute_reply.started": "2023-04-09T15:44:07.386763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing the path and keeping just the file name in story_id\n",
    "data['story_id'] = data['story_id'].apply(lambda x: x.split('/')[-1].split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:08.633976Z",
     "iopub.status.busy": "2023-04-09T15:44:08.633222Z",
     "iopub.status.idle": "2023-04-09T15:44:08.675563Z",
     "shell.execute_reply": "2023-04-09T15:44:08.674409Z",
     "shell.execute_reply.started": "2023-04-09T15:44:08.633941Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv('/kaggle/working/news111/newsqa-data-formatted.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:14.030836Z",
     "iopub.status.busy": "2023-04-09T15:44:14.030123Z",
     "iopub.status.idle": "2023-04-09T15:44:14.038762Z",
     "shell.execute_reply": "2023-04-09T15:44:14.037581Z",
     "shell.execute_reply.started": "2023-04-09T15:44:14.030797Z"
    }
   },
   "outputs": [],
   "source": [
    "# We don't need is_answer_absent and is_question_bad columns\n",
    "data = data.drop(['is_answer_absent', 'is_question_bad'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:14.577133Z",
     "iopub.status.busy": "2023-04-09T15:44:14.576098Z",
     "iopub.status.idle": "2023-04-09T15:44:14.668237Z",
     "shell.execute_reply": "2023-04-09T15:44:14.667278Z",
     "shell.execute_reply.started": "2023-04-09T15:44:14.577084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading stories\n",
    "NEWS_STORIES = utils.open_pickle('/kaggle/working/news111/news_stories.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:14.970636Z",
     "iopub.status.busy": "2023-04-09T15:44:14.969516Z",
     "iopub.status.idle": "2023-04-09T15:44:14.982176Z",
     "shell.execute_reply": "2023-04-09T15:44:14.980761Z",
     "shell.execute_reply.started": "2023-04-09T15:44:14.970581Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_answer_range(story_id, answer_range):\n",
    "    '''Checks if answer range starts or ends in the middle of a words\n",
    "    and returns the correct answer range along with answer text'''\n",
    "    \n",
    "    # If answer is not available, denote it as -1\n",
    "    if answer_range == 'None':\n",
    "        return [-1, -1]\n",
    "    \n",
    "    story = NEWS_STORIES[story_id]\n",
    "    \n",
    "    # Check for errors in answer\n",
    "    if len(answer_range.split(':')) == 1:\n",
    "        return [-1, -1]\n",
    "    \n",
    "    start_idx, end_idx = answer_range.split(':')\n",
    "    start_idx, end_idx = int(start_idx), int(end_idx)\n",
    "    \n",
    "    # Moves back start_idx to the start of a word\n",
    "    while start_idx != 0 and not utils.is_whitespace(story[start_idx - 1]) and not utils.is_punct(story[start_idx - 1]):\n",
    "        start_idx = start_idx - 1\n",
    "    \n",
    "    # Some ranges end with a punctuation or a whitespace\n",
    "    if utils.is_whitespace(story[end_idx - 1]) or utils.is_punct(story[end_idx - 1]):\n",
    "        end_idx = end_idx - 1\n",
    "    \n",
    "    # Moves end_idx to the end of a word\n",
    "    while not utils.is_whitespace(story[end_idx]) and not utils.is_punct(story[end_idx + 1]):\n",
    "        end_idx = end_idx + 1\n",
    "        \n",
    "    # There are some answers with \\n at the end followed by a letter\n",
    "    # The answer will not be in two different paragraphs\n",
    "    answer_text = story[start_idx:end_idx]\n",
    "    answer_para = re.split('\\n', answer_text)\n",
    "    \n",
    "    if len(answer_para[-1]) > len(answer_para[0]):\n",
    "        start_idx = end_idx - len(answer_para[-1])\n",
    "        answer_text = answer_para[-1]\n",
    "    else:\n",
    "        end_idx = start_idx + len(answer_para[0])\n",
    "        answer_text = answer_para[0]\n",
    "    \n",
    "    return [start_idx, end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:15.434574Z",
     "iopub.status.busy": "2023-04-09T15:44:15.433405Z",
     "iopub.status.idle": "2023-04-09T15:44:15.443496Z",
     "shell.execute_reply": "2023-04-09T15:44:15.442431Z",
     "shell.execute_reply.started": "2023-04-09T15:44:15.434529Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_answer(qa_details):\n",
    "    '''A function that selects an answer for a question\n",
    "    \n",
    "    > If validated answers are available, the one with most votes is selected\n",
    "    > If there's a tie in validated answer votes or if validated answer is not\n",
    "      available, the most frequent answer is selected\n",
    "    > If there's a tie here too, a random answer is selected'''\n",
    "    \n",
    "    # If validated answers are available, select the one with most votes\n",
    "    if qa_details['validated_answers'] is not np.nan:\n",
    "        validated_answers = eval(qa_details['validated_answers'])\n",
    "        \n",
    "        # Get the answers with maximum votes\n",
    "        max_vote_ans = utils.get_max_keys(validated_answers)\n",
    "        \n",
    "        # Check for ties\n",
    "        if len(max_vote_ans) == 1:\n",
    "            return adjust_answer_range(qa_details['story_id'], max_vote_ans[0])\n",
    "    \n",
    "    # If validated answers are not available or if there is a tie in validated answers\n",
    "    # Get all available answers\n",
    "    answers = re.split(',|\\|', qa_details['answer_char_ranges'])\n",
    "    \n",
    "    # If there is just one answer\n",
    "    if len(answers) == 1:\n",
    "        return adjust_answer_range(qa_details['story_id'], answers[0])\n",
    "    \n",
    "    # Get counts of each answer\n",
    "    answer_freq = utils.get_frequency(answers)\n",
    "    max_vote_ans = utils.get_max_keys(answer_freq)\n",
    "    \n",
    "    if len(max_vote_ans) == 1:\n",
    "        return adjust_answer_range(qa_details['story_id'], max_vote_ans[0])\n",
    "    \n",
    "    # If there is a tie for multiple answers, return a random answer\n",
    "    return adjust_answer_range(qa_details['story_id'], random.choice(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:15.704838Z",
     "iopub.status.busy": "2023-04-09T15:44:15.704238Z",
     "iopub.status.idle": "2023-04-09T15:44:16.259932Z",
     "shell.execute_reply": "2023-04-09T15:44:16.258884Z",
     "shell.execute_reply.started": "2023-04-09T15:44:15.704808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select one answer range among multiple answers\n",
    "data[['start_idx', 'end_idx']] = data.apply(get_answer, axis = 1, result_type = 'expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:16.262493Z",
     "iopub.status.busy": "2023-04-09T15:44:16.262092Z",
     "iopub.status.idle": "2023-04-09T15:44:16.276498Z",
     "shell.execute_reply": "2023-04-09T15:44:16.275325Z",
     "shell.execute_reply.started": "2023-04-09T15:44:16.262456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_char_ranges</th>\n",
       "      <th>validated_answers</th>\n",
       "      <th>start_idx</th>\n",
       "      <th>end_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43a488c2d73b4f34122fc92c8df0467078699156</td>\n",
       "      <td>When was the plane crash?</td>\n",
       "      <td>2794:2805,372:382|398:410|372:382</td>\n",
       "      <td>{\"none\": 2}</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91607b09ab00b8dff5d7b98387ed132a44d8b61b</td>\n",
       "      <td>Where has Musharraf lived in exile?</td>\n",
       "      <td>1018:1035|1008:1035|1018:1035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d0a418c3fad00479e73f9786b5e745ae6e844972</td>\n",
       "      <td>Who issued a travel health warning?</td>\n",
       "      <td>615:619|611:619,626:628,650:704,711:713,720:72...</td>\n",
       "      <td>{\"none\": 2, \"650:704\": 1}</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e7b3db6969c8ed2687e4bcaaa380ff3e93852bf</td>\n",
       "      <td>What has become his highest grossing film sinc...</td>\n",
       "      <td>2592:2615|179:192|502:517</td>\n",
       "      <td>{\"502:517\": 2, \"2592:2615\": 1}</td>\n",
       "      <td>499</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bd2671153b0103b968eaebc3d23435fc20cc999c</td>\n",
       "      <td>Where is the resting place of Spanish poet Fed...</td>\n",
       "      <td>None|272:279|2060:2084</td>\n",
       "      <td>{\"none\": 2}</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   story_id  \\\n",
       "0  43a488c2d73b4f34122fc92c8df0467078699156   \n",
       "1  91607b09ab00b8dff5d7b98387ed132a44d8b61b   \n",
       "2  d0a418c3fad00479e73f9786b5e745ae6e844972   \n",
       "3  1e7b3db6969c8ed2687e4bcaaa380ff3e93852bf   \n",
       "4  bd2671153b0103b968eaebc3d23435fc20cc999c   \n",
       "\n",
       "                                            question  \\\n",
       "0                          When was the plane crash?   \n",
       "1                Where has Musharraf lived in exile?   \n",
       "2                Who issued a travel health warning?   \n",
       "3  What has become his highest grossing film sinc...   \n",
       "4  Where is the resting place of Spanish poet Fed...   \n",
       "\n",
       "                                  answer_char_ranges  \\\n",
       "0                  2794:2805,372:382|398:410|372:382   \n",
       "1                      1018:1035|1008:1035|1018:1035   \n",
       "2  615:619|611:619,626:628,650:704,711:713,720:72...   \n",
       "3                          2592:2615|179:192|502:517   \n",
       "4                             None|272:279|2060:2084   \n",
       "\n",
       "                validated_answers  start_idx  end_idx  \n",
       "0                     {\"none\": 2}         -1       -1  \n",
       "1                             NaN       1017     1038  \n",
       "2       {\"none\": 2, \"650:704\": 1}         -1       -1  \n",
       "3  {\"502:517\": 2, \"2592:2615\": 1}        499      522  \n",
       "4                     {\"none\": 2}         -1       -1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:16.836810Z",
     "iopub.status.busy": "2023-04-09T15:44:16.835876Z",
     "iopub.status.idle": "2023-04-09T15:44:16.841996Z",
     "shell.execute_reply": "2023-04-09T15:44:16.840639Z",
     "shell.execute_reply.started": "2023-04-09T15:44:16.836744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Total examples in the dataset\n",
    "total_examples = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:17.566013Z",
     "iopub.status.busy": "2023-04-09T15:44:17.565659Z",
     "iopub.status.idle": "2023-04-09T15:44:17.571916Z",
     "shell.execute_reply": "2023-04-09T15:44:17.570854Z",
     "shell.execute_reply.started": "2023-04-09T15:44:17.565981Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_tokenizer(doc, model=en):\n",
    "    # a simple tokenizer for individual documents\n",
    "    parsed = model(doc)\n",
    "    return([t.lower_ for t in parsed if (t.is_alpha)&(not t.like_url)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:18.066444Z",
     "iopub.status.busy": "2023-04-09T15:44:18.065669Z",
     "iopub.status.idle": "2023-04-09T15:44:18.076342Z",
     "shell.execute_reply": "2023-04-09T15:44:18.075329Z",
     "shell.execute_reply.started": "2023-04-09T15:44:18.066405Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_doc_embedding(tokens, model = nlp):\n",
    "    '''Returns the embedding of a document by averaging the\n",
    "    GloVe embeddings of all tokens in the document'''\n",
    "    \n",
    "    embeddings = []\n",
    "    for t in tokens:\n",
    "        embeddings.append(model.vocab[t].vector)\n",
    "    \n",
    "    embeddings = np.array(embeddings)\n",
    "    if embeddings.ndim == 1:\n",
    "        return embeddings\n",
    "    else:\n",
    "        return np.mean(embeddings, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:18.424153Z",
     "iopub.status.busy": "2023-04-09T15:44:18.423285Z",
     "iopub.status.idle": "2023-04-09T15:44:18.433879Z",
     "shell.execute_reply": "2023-04-09T15:44:18.432279Z",
     "shell.execute_reply.started": "2023-04-09T15:44:18.424107Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_answer(text, question):\n",
    "    '''Returns the start and end indices of the sentence that\n",
    "    has the maximum cosine similarity with the question'''\n",
    "    \n",
    "    # Stores the start position of each sentence\n",
    "    sentence_to_char_idx = [0]\n",
    "    \n",
    "    sentences = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    for idx, char in enumerate(text):\n",
    "        # If the chracter is a punctuation, we append the sentence\n",
    "        if utils.is_punct(char):\n",
    "            sentences.append(text[start_idx:idx])\n",
    "            start_idx = idx + 1\n",
    "            sentence_to_char_idx.append(start_idx)\n",
    "    \n",
    "    # Getting embeddings for each sentence\n",
    "    sentence_embeddings = []\n",
    "    for s in sentences:\n",
    "        tokens = simple_tokenizer(s)\n",
    "        embd = get_doc_embedding(tokens)\n",
    "        if embd.shape == (300,):\n",
    "            sentence_embeddings.append(embd)\n",
    "    \n",
    "    sentence_embeddings = np.stack(sentence_embeddings)\n",
    "    \n",
    "    # Getting the embedding for the question\n",
    "    question_embedding = get_doc_embedding(simple_tokenizer(question))\n",
    "    question_embedding = np.expand_dims(question_embedding, axis = 0)\n",
    "    \n",
    "    #print(sentence_embeddings.shape)\n",
    "    # Get the cosine similarity of each sentence with the question\n",
    "    similarity = cosine_similarity(sentence_embeddings, question_embedding)\n",
    "    \n",
    "    # Get the sentence with the most similarity\n",
    "    best_idx = np.argmax(similarity)\n",
    "    \n",
    "    # Get the sentence start and end index\n",
    "    pred_start = sentence_to_char_idx[best_idx]\n",
    "    pred_end = sentence_to_char_idx[best_idx + 1] - 1\n",
    "    \n",
    "    return pred_start, pred_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:18.731786Z",
     "iopub.status.busy": "2023-04-09T15:44:18.731084Z",
     "iopub.status.idle": "2023-04-09T15:44:18.739626Z",
     "shell.execute_reply": "2023-04-09T15:44:18.738572Z",
     "shell.execute_reply.started": "2023-04-09T15:44:18.731727Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_start, pred_end, true_start, true_end):\n",
    "    '''Calculates the f1 score and if the predicted answer overlaps \n",
    "    with the correct one'''\n",
    "    \n",
    "    # Get the overlap\n",
    "    overlap = set(range(true_start, true_end)).intersection(range(pred_start, pred_end))\n",
    "    overlap = len(overlap)\n",
    "\n",
    "    # If either of them have no answer\n",
    "    if true_end == 0 or pred_end == 0:\n",
    "        f1_score = int(true_end == pred_end)\n",
    "        is_correct = int(end_idx == pred_end)\n",
    "        return f1_score, is_correct\n",
    "    \n",
    "    # If they don't overlap at all\n",
    "    if overlap == 0 or pred_start >= pred_end:\n",
    "        f1_score = 0\n",
    "        is_correct = 0\n",
    "        return f1_score, is_correct\n",
    "\n",
    "    # If there is an overlap, we consider it correct\n",
    "    is_correct = 1\n",
    "\n",
    "    precision = overlap / (pred_end - pred_start)\n",
    "    recall = overlap / (true_end - true_start)\n",
    "    f1_score = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return f1_score, is_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:44:19.046160Z",
     "iopub.status.busy": "2023-04-09T15:44:19.045838Z",
     "iopub.status.idle": "2023-04-09T15:49:01.846205Z",
     "shell.execute_reply": "2023-04-09T15:49:01.844714Z",
     "shell.execute_reply.started": "2023-04-09T15:44:19.046130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 8769/8769"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of this approach on the data\n",
    "\n",
    "correct = 0\n",
    "total_f1 = 0\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    text = NEWS_STORIES[row['story_id']]\n",
    "    question = row['question']\n",
    "    \n",
    "    # Get the predictions\n",
    "    pred_start, pred_end = predict_answer(text, question)\n",
    "    f1, is_correct = calculate_metrics(pred_start, pred_end, row['start_idx'], row['end_idx'])\n",
    "    \n",
    "    total_f1 += f1\n",
    "    correct += is_correct\n",
    "    \n",
    "    # Print progress\n",
    "    utils.drawProgressBar(idx + 1, total_examples)\n",
    "    \n",
    "acc = correct/total_examples\n",
    "f1_score = total_f1/total_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:49:07.892814Z",
     "iopub.status.busy": "2023-04-09T15:49:07.892434Z",
     "iopub.status.idle": "2023-04-09T15:49:07.899168Z",
     "shell.execute_reply": "2023-04-09T15:49:07.898127Z",
     "shell.execute_reply.started": "2023-04-09T15:49:07.892782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.0306\n",
      "Accuracy: 0.0928\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score: {:.4f}\".format(f1_score))\n",
    "print(\"Accuracy: {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:49:13.328871Z",
     "iopub.status.busy": "2023-04-09T15:49:13.328505Z",
     "iopub.status.idle": "2023-04-09T15:49:13.336799Z",
     "shell.execute_reply": "2023-04-09T15:49:13.335346Z",
     "shell.execute_reply.started": "2023-04-09T15:49:13.328839Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_examples():\n",
    "    '''Return a list of NewsQaExample objects'''\n",
    "    \n",
    "    # If a pickle file exists for examples, read the file\n",
    "    if os.path.isfile('/kaggle/working/news111/examples_sample.pkl'):\n",
    "        return utils.open_pickle('/kaggle/working/news111/examples_sample.pkl')\n",
    "    \n",
    "    examples = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        ex = NewsQaExample(NEWS_STORIES[row['story_id']], row['question'], row['start_idx'], row['end_idx'])\n",
    "        examples.append(ex)\n",
    "        utils.drawProgressBar(idx + 1, total_examples)\n",
    "    print('\\n')\n",
    "    # Saving examples to a pickle file\n",
    "    utils.save_pickle('/kaggle/working/news111/examples_sample.pkl', examples)\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:49:13.800142Z",
     "iopub.status.busy": "2023-04-09T15:49:13.799783Z",
     "iopub.status.idle": "2023-04-09T15:49:13.812042Z",
     "shell.execute_reply": "2023-04-09T15:49:13.810642Z",
     "shell.execute_reply.started": "2023-04-09T15:49:13.800112Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_datasets(examples, tokenizer_name):\n",
    "    '''Returns train, val and test datasets from examples'''\n",
    "    \n",
    "    model_name = tokenizer_name.split('-')[0]\n",
    "    \n",
    "    if os.path.isfile('/kaggle/working/news111/sample_dataset_' + model_name + '.pkl'):\n",
    "        return utils.open_pickle('/kaggle/working/news111/sample_dataset_' + model_name + '.pkl')\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    if tokenizer_name == 'bert-large-uncased-whole-word-masking-finetuned-squad':\n",
    "        tokenizer = BertTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    if tokenizer_name == 'distilbert-base-uncased-distilled-squad':\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    print(\"Getting input features:\")\n",
    "    for idx, ex in enumerate(examples):\n",
    "        input_features = ex.encode_plus(tokenizer, pad = True)\n",
    "        features.append(input_features)\n",
    "        labels.append(ex.get_label())\n",
    "        utils.drawProgressBar(idx + 1, total_examples)\n",
    "    \n",
    "    print('\\n')\n",
    "    # Getting TensorDataset\n",
    "    train_set, val_set, test_set, feature_idx_map = create_dataset(features, labels, model = model_name)\n",
    "    # Saving the dataset in a file\n",
    "    utils.save_pickle('/kaggle/working/news111/sample_dataset_' + model_name + '.pkl', (train_set, val_set, test_set, feature_idx_map))\n",
    "    \n",
    "    return (train_set, val_set, test_set, feature_idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:49:14.181059Z",
     "iopub.status.busy": "2023-04-09T15:49:14.180658Z",
     "iopub.status.idle": "2023-04-09T15:49:14.187355Z",
     "shell.execute_reply": "2023-04-09T15:49:14.186160Z",
     "shell.execute_reply.started": "2023-04-09T15:49:14.181024Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(train_set, val_set, test_set, batch_size):\n",
    "    '''Creates torch dataloaders for train, validation and test sets'''\n",
    "    \n",
    "    train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, \n",
    "                          sampler = RandomSampler(train_set))\n",
    "\n",
    "    val_loader = DataLoader(val_set, batch_size = BATCH_SIZE, \n",
    "                            sampler = SequentialSampler(val_set))\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size = BATCH_SIZE, \n",
    "                             sampler = SequentialSampler(test_set))\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:49:19.049496Z",
     "iopub.status.busy": "2023-04-09T15:49:19.048683Z",
     "iopub.status.idle": "2023-04-09T15:49:19.058471Z",
     "shell.execute_reply": "2023-04-09T15:49:19.057336Z",
     "shell.execute_reply.started": "2023-04-09T15:49:19.049456Z"
    }
   },
   "outputs": [],
   "source": [
    "def finetune_model(model_name, train_loader, val_loader, feature_idx_map, device, \n",
    "                   epochs = 1, learning_rate = 1e-5):\n",
    "    '''Fine-tunes a pretrained model'''\n",
    "    \n",
    "    if model_name == 'bert-large-uncased-whole-word-masking-finetuned-squad':\n",
    "        model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "        # Freezing bert parameters\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if model_name == 'distilbert-base-uncased-distilled-squad':\n",
    "        model = DistilBertForQuestionAnswering.from_pretrained(model_name)\n",
    "        # Freezing distilbert parameters\n",
    "        for param in model.distilbert.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    short_name = model_name.split('-')[0]\n",
    "    \n",
    "    newsqa_model = NewsQaModel(model)\n",
    "    newsqa_model.train(train_loader, val_loader, feature_idx_map, device, \n",
    "                       num_epochs = epochs, lr = learning_rate, \n",
    "                       filename = '/kaggle/working/news111' + short_name + '_sample.pt')\n",
    "    \n",
    "    return newsqa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:49:19.617705Z",
     "iopub.status.busy": "2023-04-09T15:49:19.615095Z",
     "iopub.status.idle": "2023-04-09T15:50:40.703051Z",
     "shell.execute_reply": "2023-04-09T15:50:40.701918Z",
     "shell.execute_reply.started": "2023-04-09T15:49:19.617665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 8769/8769\n",
      "\n",
      "Variable successfully saved in /kaggle/working/news111/examples_sample.pkl\n"
     ]
    }
   ],
   "source": [
    "# Get a list of NewsQaExample objects\n",
    "examples = get_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:51:17.713429Z",
     "iopub.status.busy": "2023-04-09T15:51:17.712364Z",
     "iopub.status.idle": "2023-04-09T15:51:17.718861Z",
     "shell.execute_reply": "2023-04-09T15:51:17.717540Z",
     "shell.execute_reply.started": "2023-04-09T15:51:17.713383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining model name\n",
    "bert_model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:51:19.470192Z",
     "iopub.status.busy": "2023-04-09T15:51:19.469266Z",
     "iopub.status.idle": "2023-04-09T15:58:02.286303Z",
     "shell.execute_reply": "2023-04-09T15:58:02.285131Z",
     "shell.execute_reply.started": "2023-04-09T15:51:19.470140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69fb513bdc9480497baf77a5b00ba24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting input features:\n",
      "Progress: [====================] 8769/8769\n",
      "\n",
      "Variable successfully saved in /kaggle/working/news111/sample_dataset_bert.pkl\n"
     ]
    }
   ],
   "source": [
    "# Getting the training, validation and test sets\n",
    "bert_datasets = get_datasets(examples, bert_model_name)\n",
    "bert_train_set, bert_val_set, bert_test_set, bert_feature_idx_map = bert_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:58:04.414330Z",
     "iopub.status.busy": "2023-04-09T15:58:04.413604Z",
     "iopub.status.idle": "2023-04-09T15:58:04.420547Z",
     "shell.execute_reply": "2023-04-09T15:58:04.419496Z",
     "shell.execute_reply.started": "2023-04-09T15:58:04.414280Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "bert_loaders = get_dataloaders(bert_train_set, bert_val_set, bert_test_set, batch_size = BATCH_SIZE)\n",
    "bert_train_loader, bert_val_loader, bert_test_loader = bert_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T15:58:07.120773Z",
     "iopub.status.busy": "2023-04-09T15:58:07.120007Z",
     "iopub.status.idle": "2023-04-09T16:36:34.571699Z",
     "shell.execute_reply": "2023-04-09T16:36:34.570073Z",
     "shell.execute_reply.started": "2023-04-09T15:58:07.120722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8740ae9514f4fc2a3756f56289ce971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3d3e8caf4249e6854ead44997e5f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "Progress: [====================] 192/192  12m 30s\tloss: 3.8827\tf1: 0.2501\tacc: 0.4377\tval_loss: 3.7162\tval_f1: 0.2864\tval_acc: 0.4438\n",
      "Validation accuracy increased from 0.0000 to 0.4438, saving to /kaggle/working/news111bert_sample.pt\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/3:\n",
      "Progress: [====================] 192/192  12m 26s\tloss: 3.6125\tf1: 0.2736\tacc: 0.4705\tval_loss: 3.6087\tval_f1: 0.2986\tval_acc: 0.4490\n",
      "Validation accuracy increased from 0.4438 to 0.4490, saving to /kaggle/working/news111bert_sample.pt\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/3:\n",
      "Progress: [====================] 192/192  12m 27s\tloss: 3.5578\tf1: 0.2811\tacc: 0.4753\tval_loss: 3.5600\tval_f1: 0.3016\tval_acc: 0.4602\n",
      "Validation accuracy increased from 0.4490 to 0.4602, saving to /kaggle/working/news111bert_sample.pt\n"
     ]
    }
   ],
   "source": [
    "# -- Still takes nearly 20 minutes to run --\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "bert_model = finetune_model(bert_model_name, bert_train_loader, bert_val_loader, bert_feature_idx_map,device, epochs = EPOCHS, learning_rate = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T16:36:44.545354Z",
     "iopub.status.busy": "2023-04-09T16:36:44.544967Z",
     "iopub.status.idle": "2023-04-09T19:02:46.889783Z",
     "shell.execute_reply": "2023-04-09T19:02:46.888580Z",
     "shell.execute_reply.started": "2023-04-09T16:36:44.545320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 55/55\n",
      "loss: 3.4567\tf1:0.3269\tacc:0.5084\n"
     ]
    }
   ],
   "source": [
    "# Evaluation the performance on test set\n",
    "bert_model.load('/kaggle/working/news111bert_sample.pt')\n",
    "bert_eval_metrics = bert_model.evaluate(bert_test_loader, bert_feature_idx_map, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T19:03:01.292412Z",
     "iopub.status.busy": "2023-04-09T19:03:01.291619Z",
     "iopub.status.idle": "2023-04-09T19:06:15.577035Z",
     "shell.execute_reply": "2023-04-09T19:06:15.575957Z",
     "shell.execute_reply.started": "2023-04-09T19:03:01.292371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 55/55\n",
      "loss: 6.0434\tf1:0.2818\tacc:0.4625\n"
     ]
    }
   ],
   "source": [
    "# Evalutating performance on the model without fine-tuining\n",
    "bert_non_finetuned = BertForQuestionAnswering.from_pretrained(bert_model_name)\n",
    "bert_non_finetuned.to(device)\n",
    "\n",
    "bert_newsqa_model = NewsQaModel(bert_non_finetuned)\n",
    "\n",
    "non_finetuned_eval_metrics = bert_newsqa_model.evaluate(bert_test_loader, bert_feature_idx_map, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T19:08:00.630874Z",
     "iopub.status.busy": "2023-04-09T19:08:00.629934Z",
     "iopub.status.idle": "2023-04-09T19:08:00.635913Z",
     "shell.execute_reply": "2023-04-09T19:08:00.634506Z",
     "shell.execute_reply.started": "2023-04-09T19:08:00.630815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining model name\n",
    "dbert_model_name = 'distilbert-base-uncased-distilled-squad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T19:08:02.172793Z",
     "iopub.status.busy": "2023-04-09T19:08:02.172058Z",
     "iopub.status.idle": "2023-04-09T19:14:43.166452Z",
     "shell.execute_reply": "2023-04-09T19:14:43.165312Z",
     "shell.execute_reply.started": "2023-04-09T19:08:02.172754Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0b92689c234d74a3d35dec693ec48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting input features:\n",
      "Progress: [====================] 8769/8769\n",
      "\n",
      "Variable successfully saved in /kaggle/working/news111/sample_dataset_distilbert.pkl\n"
     ]
    }
   ],
   "source": [
    "# Getting the training, validation and test sets\n",
    "dbert_datasets = get_datasets(examples, dbert_model_name)\n",
    "dbert_train_set, dbert_val_set, dbert_test_set, dbert_feature_idx_map = dbert_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T19:14:52.631054Z",
     "iopub.status.busy": "2023-04-09T19:14:52.630636Z",
     "iopub.status.idle": "2023-04-09T19:14:52.640831Z",
     "shell.execute_reply": "2023-04-09T19:14:52.639339Z",
     "shell.execute_reply.started": "2023-04-09T19:14:52.631020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dbert_loaders = get_dataloaders(dbert_train_set, dbert_val_set, dbert_test_set, batch_size = BATCH_SIZE)\n",
    "dbert_train_loader, dbert_val_loader, dbert_test_loader = dbert_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T19:14:54.447220Z",
     "iopub.status.busy": "2023-04-09T19:14:54.446525Z",
     "iopub.status.idle": "2023-04-09T19:20:48.298206Z",
     "shell.execute_reply": "2023-04-09T19:20:48.295454Z",
     "shell.execute_reply.started": "2023-04-09T19:14:54.447184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb1a20756d6478bb01a5e52d0c5bf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/451 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c366b58a4dfc45cc937e70cd43675a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:\n",
      "Progress: [====================] 192/192  1m 54s\tloss: 4.1987\tf1: 0.2516\tacc: 0.3645\tval_loss: 3.8669\tval_f1: 0.2764\tval_acc: 0.3925\n",
      "Validation accuracy increased from 0.0000 to 0.3925, saving to /kaggle/working/news111distilbert_sample.pt\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/3:\n",
      "Progress: [====================] 192/192  1m 54s\tloss: 3.9483\tf1: 0.2591\tacc: 0.3742\tval_loss: 3.7540\tval_f1: 0.2943\tval_acc: 0.4148\n",
      "Validation accuracy increased from 0.3925 to 0.4148, saving to /kaggle/working/news111distilbert_sample.pt\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/3:\n",
      "Progress: [====================] 192/192  1m 54s\tloss: 3.9038\tf1: 0.2630\tacc: 0.3803\tval_loss: 3.7200\tval_f1: 0.2994\tval_acc: 0.4293\n",
      "Validation accuracy increased from 0.4148 to 0.4293, saving to /kaggle/working/news111distilbert_sample.pt\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "dbert_model = finetune_model(dbert_model_name, dbert_train_loader, dbert_val_loader, dbert_feature_idx_map, \n",
    "                             device, epochs = EPOCHS, learning_rate = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T19:21:24.860072Z",
     "iopub.status.busy": "2023-04-09T19:21:24.859074Z",
     "iopub.status.idle": "2023-04-09T19:42:52.191160Z",
     "shell.execute_reply": "2023-04-09T19:42:52.190080Z",
     "shell.execute_reply.started": "2023-04-09T19:21:24.860029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 55/55\n",
      "loss: 3.7215\tf1:0.3027\tacc:0.4302\n"
     ]
    }
   ],
   "source": [
    "# Evaluation the performance on test set\n",
    "dbert_model.load('/kaggle/working/news111distilbert_sample.pt')\n",
    "dbert_eval_metrics = dbert_model.evaluate(dbert_test_loader, dbert_feature_idx_map, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-09T19:44:08.380134Z",
     "iopub.status.busy": "2023-04-09T19:44:08.378971Z",
     "iopub.status.idle": "2023-04-09T19:44:37.305204Z",
     "shell.execute_reply": "2023-04-09T19:44:37.304058Z",
     "shell.execute_reply.started": "2023-04-09T19:44:08.380075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 55/55\n",
      "loss: 6.4390\tf1:0.2873\tacc:0.4164\n"
     ]
    }
   ],
   "source": [
    "# Evalutating performance on the model without fine-tuining\n",
    "dbert_non_finetuned = DistilBertForQuestionAnswering.from_pretrained(dbert_model_name)\n",
    "dbert_non_finetuned.to(device)\n",
    "\n",
    "dbert_newsqa_model = NewsQaModel(dbert_non_finetuned)\n",
    "\n",
    "non_finetuned_eval_metrics = dbert_newsqa_model.evaluate(dbert_test_loader, dbert_feature_idx_map, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
